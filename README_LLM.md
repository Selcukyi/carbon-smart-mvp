# Carbon Emission App - LLM Entegrasyonu

Bu proje, gerÃ§ek LLM (Large Language Model) entegrasyonu ile Ã§alÄ±ÅŸan bir karbon emisyonu yÃ¶netim uygulamasÄ±dÄ±r.

## ğŸš€ Ã–zellikler

### Backend LLM Entegrasyonu
- **OpenAI GPT-4** entegrasyonu
- **GerÃ§ek AI analizi** ve Ã¶neriler
- **Risk deÄŸerlendirmesi** 
- **Performans metrikleri**
- **Fallback sistem** (API key yoksa mock data)

### Frontend LLM Ã–zellikleri
- **GerÃ§ek zamanlÄ± AI analizi**
- **Loading states** ve error handling
- **Yenile butonu** ile manuel gÃ¼ncelleme
- **Responsive tasarÄ±m**

## ğŸ› ï¸ Kurulum

### 1. Backend Kurulumu

```bash
cd backend
pip install -r requirements.txt
```

### 2. OpenAI API Key Ayarlama

```bash
# Environment variable olarak
export OPENAI_API_KEY="your-openai-api-key-here"

# Veya .env dosyasÄ± oluÅŸtur
echo "OPENAI_API_KEY=your-openai-api-key-here" > .env
```

### 3. Backend BaÅŸlatma

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 4. Frontend Kurulumu

```bash
cd frontend
npm install
```

### 5. Frontend BaÅŸlatma

```bash
npm run dev
```

## ğŸ“Š LLM API Endpoints

### 1. Emisyon Analizi
```
GET /api/llm/analysis
```
AI-powered emisyon analizi ve executive summary

### 2. Ã–neriler
```
GET /api/llm/recommendations
```
Karbon azaltma Ã¶nerileri ve ROI hesaplamalarÄ±

### 3. Risk DeÄŸerlendirmesi
```
GET /api/llm/risk-assessment
```
Karbon riskleri ve azaltma stratejileri

### 4. TÃ¼m Ä°Ã§gÃ¶rÃ¼ler
```
GET /api/llm/insights
```
TÃ¼m LLM analizlerini tek seferde getir

### 5. Ã–zel Veri Analizi
```
POST /api/llm/analyze-custom-data
Content-Type: application/json

{
  "total_emissions": 2847,
  "scope1": 1247,
  "scope2": 1456,
  "scope3": 144,
  "eu_ets_allowances": 2600,
  "eu_ets_used": 2847,
  "eu_ets_price": 85.50
}
```

## ğŸ¤– LLM Servis Ã–zellikleri

### Analiz TÃ¼rleri
1. **Executive Summary**: YÃ¶netici Ã¶zeti ve ana bulgular
2. **Key Findings**: Temel bulgular ve Ã¶ncelik alanlarÄ±
3. **Financial Impact**: Finansal etki analizi
4. **Compliance Status**: Uyumluluk durumu

### Ã–neriler
- **BaÅŸlÄ±k ve aÃ§Ä±klama**
- **Maliyet tahmini**
- **YÄ±llÄ±k tasarruf**
- **Uygulama sÃ¼resi**
- **Ã–ncelik seviyesi** (high/medium/low)
- **Beklenen emisyon azaltÄ±mÄ±**

### Risk Analizi
- **Risk kategorileri**: Uyumluluk, finansal, operasyonel, reputasyon
- **OlasÄ±lÄ±k deÄŸerlendirmesi**: High/Medium/Low
- **Etki analizi**: â‚¬ miktarÄ±
- **Azaltma stratejileri**

## ğŸ”§ KonfigÃ¼rasyon

### Backend Config
```python
# app/core/config.py
class Settings(BaseSettings):
    openai_api_key: str = ""  # OpenAI API key
    environment: str = "development"
    database_url: str = "sqlite:///./carbon_mvp.db"
```

### Frontend Config
```javascript
// src/lib/config.js
export const FEATURE_FLAGS = {
  MOCK: false, // GerÃ§ek LLM API'sini kullan
};

export const BACKEND_URL = "http://localhost:8000";
```

## ğŸ§ª Test

### LLM Servis Testi
```bash
cd backend
python3 test_llm.py
```

### API Testi
```bash
# Emisyon analizi
curl http://localhost:8000/api/llm/analysis

# TÃ¼m iÃ§gÃ¶rÃ¼ler
curl http://localhost:8000/api/llm/insights
```

## ğŸ“ˆ KullanÄ±m SenaryolarÄ±

### 1. GerÃ§ek ZamanlÄ± Analiz
- Dashboard'da "ğŸ”„ Yenile" butonuna tÄ±klayÄ±n
- AI verilerinizi analiz eder ve yeni Ã¶neriler sunar

### 2. Ã–zel Veri Analizi
- Upload sayfasÄ±ndan veri yÃ¼kleyin
- AI otomatik olarak analiz eder ve Ã¶neriler sunar

### 3. Risk YÃ¶netimi
- Allowances sayfasÄ±nda risk analizi gÃ¶rÃ¼ntÃ¼leyin
- AI riskleri deÄŸerlendirir ve azaltma stratejileri Ã¶nerir

## ğŸ”’ GÃ¼venlik

- API key'ler environment variable olarak saklanÄ±r
- Fallback sistem API key yoksa mock data kullanÄ±r
- CORS ayarlarÄ± yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r

## ğŸš¨ Hata YÃ¶netimi

### Backend
- OpenAI API hatalarÄ±nda fallback responses
- DetaylÄ± logging ve error handling
- Graceful degradation

### Frontend
- Loading states ve error messages
- Fallback to mock data
- User-friendly error notifications

## ğŸ“ Notlar

- OpenAI API key olmadan da Ã§alÄ±ÅŸÄ±r (fallback mode)
- GerÃ§ek LLM analizi iÃ§in OpenAI API key gerekli
- TÃ¼m analizler TÃ¼rkÃ§e ve Ä°ngilizce destekler
- Response'lar JSON formatÄ±nda dÃ¶ner

## ğŸ”„ GÃ¼ncellemeler

- LLM analizleri cache'lenmez, her seferinde fresh data
- Manual refresh butonu ile yeniden analiz
- Real-time data processing